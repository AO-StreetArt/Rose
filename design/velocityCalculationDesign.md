* For each frame:
    - After the object detection, depth estimation, and image segmentation on the frame is complete, send the results back to another method, identify_objects_with_velocity, on a separate thread.  The results of this method should be written to the terminal when they return, and we should not wait for this to return to draw the results of the initial analysis.
    - In this new method, we take as an input the results of object detection, depth estimation, and image segmentation.  Then, for each result:
        -- If MemoryImageStorage is empty, populate it with the results of object detection, with a depth metadata entry populated with data from the DepthEstimation algorithm, using the estimated depth at any point determined to be a part of the object by ImageSegmentation.  Store the bounding box as a separate metadata entry, and the object name as a tag.
        -- check the MemoryImageStorage data structure for any images with matching tags to the object name that was detected.  For each image returned, use the image_comparator.py file to determine if the subsection of the original image defined by the detected object's bounding box is a match to the stored file.  If so, then add a metadata tag to the entry in MemoryImageStorage, and the entry being built, with a generated UUID that is a 'MatchId'.  Then, we do a 3D distance calculation between the previous and current image segments, using the center point of the bounding box as the X and Y coordinates, and the depth estimate from any point determined to be a part of the object by ImageSegmentation as the Z coordinate.  Store the velocity as another metadata attribute on the new record, along with the bounding box.  Store the object name as a tag.  Before saving the new entries into MemoryImageStorage, sync the existing data to Redis and clear it from the MemoryImageStorage.